{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7 Exercise: Evaluate and Analyze Q&A Model Performance (SOLUTION)\n",
    "\n",
    "**Estimated Time:** 17 minutes\n",
    "\n",
    "## Scenario\n",
    "\n",
    "Your Q&A model achieves **78% F1** but management sees user complaints about wrong answers.\n",
    "\n",
    "**Questions to answer:**\n",
    "- Are mistakes on long contexts?\n",
    "- Unanswerable questions?\n",
    "- Specific question types?\n",
    "\n",
    "**Goal:** Perform systematic error analysis to prioritize improvements!\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Install if needed\n",
    "# !pip install transformers datasets evaluate pandas matplotlib torch\n",
    "\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part A: Generate Predictions and Compute Metrics (6 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load BERT Q&A Model\n",
    "\n",
    "We'll use the same BERT from Lesson 6, now fine-tuned for Q&A!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT Q&A model...\n",
      "(First run will download ~400MB model)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ BERT Q&A model loaded on CPU\n",
      "  This is the same BERT architecture from Lesson 6!\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Load BERT Q&A model\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "print(\"Loading BERT Q&A model...\")\n",
    "print(\"(First run will download ~400MB model)\\n\")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"deepset/bert-base-cased-squad2\",\n",
    "    tokenizer=\"deepset/bert-base-cased-squad2\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"âœ“ BERT Q&A model loaded on {'GPU' if device == 0 else 'CPU'}\")\n",
    "print(\"  This is the same BERT architecture from Lesson 6!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load SQuAD 2.0 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SQuAD 2.0 validation set...\n",
      "âœ“ Loaded 250 examples\n",
      "\n",
      "Sample question:\n",
      "Q: In what country is Normandy located?\n",
      "Context: The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a r...\n",
      "Answer: France\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Load SQuAD 2.0\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading SQuAD 2.0 validation set...\")\n",
    "dataset = load_dataset(\"squad_v2\", split=\"validation[:250]\")\n",
    "print(f\"âœ“ Loaded {len(dataset)} examples\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample question:\")\n",
    "print(f\"Q: {dataset[0]['question']}\")\n",
    "print(f\"Context: {dataset[0]['context'][:150]}...\")\n",
    "print(f\"Answer: {dataset[0]['answers']['text'][0] if dataset[0]['answers']['text'] else '[Unanswerable]'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Predictions with BERT\n",
    "\n",
    "We'll get top-5 predictions for ranking metrics later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions with BERT...\n",
      "(This will take 2-3 minutes on CPU)\n",
      "\n",
      "  Processed 25/250 examples...\n",
      "  Processed 50/250 examples...\n",
      "  Processed 75/250 examples...\n",
      "  Processed 100/250 examples...\n",
      "  Processed 125/250 examples...\n",
      "  Processed 150/250 examples...\n",
      "  Processed 175/250 examples...\n",
      "  Processed 200/250 examples...\n",
      "  Processed 225/250 examples...\n",
      "  Processed 250/250 examples...\n",
      "\n",
      "âœ“ Generated 250 predictions!\n",
      "\n",
      "Quick stats:\n",
      "  Correct (EM=100%): 83 (33.2%)\n",
      "  Errors (F1<100%):  167 (66.8%)\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Generate predictions with BERT (with top-K for ranking metrics)\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Helper functions for metrics\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Normalize answer text.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, ground_truth):\n",
    "    return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def compute_f1(prediction, ground_truth):\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    truth_tokens = normalize_answer(ground_truth).split()\n",
    "    \n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return float(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common = Counter(pred_tokens) & Counter(truth_tokens)\n",
    "    num_common = sum(common.values())\n",
    "    \n",
    "    if num_common == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = num_common / len(pred_tokens)\n",
    "    recall = num_common / len(truth_tokens)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1\n",
    "\n",
    "print(\"Generating predictions with BERT...\")\n",
    "print(\"(This will take 2-3 minutes on CPU)\\n\")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i, example in enumerate(dataset):\n",
    "    if (i + 1) % 25 == 0:\n",
    "        print(f\"  Processed {i + 1}/250 examples...\")\n",
    "    \n",
    "    try:\n",
    "        # Get top-5 predictions for ranking metrics\n",
    "        result = qa_pipeline(\n",
    "            question=example['question'],\n",
    "            context=example['context'],\n",
    "            top_k=5  # Get top 5 for ranking metrics!\n",
    "        )\n",
    "        \n",
    "        # Handle both single and multiple results\n",
    "        if isinstance(result, list):\n",
    "            prediction_text = result[0]['answer']\n",
    "            score = result[0]['score']\n",
    "            top_k_predictions = [{'text': r['answer'], 'score': r['score']} for r in result]\n",
    "        else:\n",
    "            prediction_text = result['answer']\n",
    "            score = result['score']\n",
    "            top_k_predictions = [{'text': result['answer'], 'score': result['score']}]\n",
    "    except Exception as e:\n",
    "        prediction_text = \"\"\n",
    "        score = 0.0\n",
    "        top_k_predictions = [{'text': '', 'score': 0.0}]\n",
    "    \n",
    "    # Get ground truth\n",
    "    is_impossible = len(example['answers']['text']) == 0\n",
    "    ground_truth = example['answers']['text'][0] if not is_impossible else \"\"\n",
    "    ground_truth_list = example['answers']['text'] if not is_impossible else []\n",
    "    \n",
    "    # Compute metrics\n",
    "    f1_score = compute_f1(prediction_text, ground_truth)\n",
    "    em_score = compute_exact_match(prediction_text, ground_truth)\n",
    "    \n",
    "    predictions.append({\n",
    "        \"id\": example['id'],\n",
    "        \"question\": example['question'],\n",
    "        \"context\": example['context'],\n",
    "        \"prediction_text\": prediction_text,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"ground_truth_list\": ground_truth_list,  # For ranking metrics\n",
    "        \"top_k_predictions\": top_k_predictions,  # For ranking metrics!\n",
    "        \"is_impossible\": is_impossible,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"em_score\": em_score,\n",
    "        \"score\": score\n",
    "    })\n",
    "\n",
    "print(f\"\\nâœ“ Generated {len(predictions)} predictions!\")\n",
    "\n",
    "# Show statistics\n",
    "total = len(predictions)\n",
    "correct = sum(1 for p in predictions if p['em_score'] == 1.0)\n",
    "errors = sum(1 for p in predictions if p['f1_score'] < 1.0)\n",
    "print(f\"\\nQuick stats:\")\n",
    "print(f\"  Correct (EM=100%): {correct} ({100*correct/total:.1f}%)\")\n",
    "print(f\"  Errors (F1<100%):  {errors} ({100*errors/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute Ranking Metrics (P@K, R@K, MRR)\n",
    "\n",
    "Since we have top-5 predictions, let's compute retrieval metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RANKING METRICS (Top-5 Predictions)\n",
      "======================================================================\n",
      "Precision@3:  46.84%\n",
      "Recall@3:     82.54%\n",
      "MRR:          0.830\n",
      "======================================================================\n",
      "\n",
      "ðŸ’¡ These metrics measure retrieval quality:\n",
      "   - P@3: What % of top-3 are correct (quality)\n",
      "   - R@3: Do we get all correct answers in top-3 (coverage)\n",
      "   - MRR: How high is the first correct answer ranked (UX)\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Compute ranking metrics\n",
    "def compute_precision_at_k(ranked_predictions, ground_truths, k=3):\n",
    "    \"\"\"What fraction of top-K are correct?\"\"\"\n",
    "    if not ranked_predictions or not ground_truths:\n",
    "        return 0.0\n",
    "    \n",
    "    top_k = ranked_predictions[:k]\n",
    "    correct = 0\n",
    "    \n",
    "    for pred in top_k:\n",
    "        pred_text = pred['text'] if isinstance(pred, dict) else pred\n",
    "        pred_normalized = normalize_answer(pred_text)\n",
    "        for truth in ground_truths:\n",
    "            if normalize_answer(truth) == pred_normalized:\n",
    "                correct += 1\n",
    "                break\n",
    "    \n",
    "    return correct / k\n",
    "\n",
    "def compute_recall_at_k(ranked_predictions, ground_truths, k=3):\n",
    "    \"\"\"What fraction of correct answers appear in top-K?\"\"\"\n",
    "    if not ground_truths:\n",
    "        return 0.0\n",
    "    if not ranked_predictions:\n",
    "        return 0.0\n",
    "    \n",
    "    top_k = ranked_predictions[:k]\n",
    "    found = 0\n",
    "    \n",
    "    for truth in ground_truths:\n",
    "        truth_normalized = normalize_answer(truth)\n",
    "        for pred in top_k:\n",
    "            pred_text = pred['text'] if isinstance(pred, dict) else pred\n",
    "            if normalize_answer(pred_text) == truth_normalized:\n",
    "                found += 1\n",
    "                break\n",
    "    \n",
    "    return found / len(ground_truths)\n",
    "\n",
    "def compute_reciprocal_rank(ranked_predictions, ground_truths):\n",
    "    \"\"\"Return 1/rank of first correct answer.\"\"\"\n",
    "    if not ranked_predictions or not ground_truths:\n",
    "        return 0.0\n",
    "    \n",
    "    for rank, pred in enumerate(ranked_predictions, start=1):\n",
    "        pred_text = pred['text'] if isinstance(pred, dict) else pred\n",
    "        pred_normalized = normalize_answer(pred_text)\n",
    "        for truth in ground_truths:\n",
    "            if normalize_answer(truth) == pred_normalized:\n",
    "                return 1.0 / rank\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "# Compute ranking metrics for answerable questions\n",
    "answerable_preds = [p for p in predictions if not p['is_impossible']]\n",
    "\n",
    "precision_at_3_scores = []\n",
    "recall_at_3_scores = []\n",
    "mrr_scores = []\n",
    "\n",
    "for pred in answerable_preds:\n",
    "    p_at_3 = compute_precision_at_k(pred['top_k_predictions'], pred['ground_truth_list'], k=3)\n",
    "    r_at_3 = compute_recall_at_k(pred['top_k_predictions'], pred['ground_truth_list'], k=3)\n",
    "    rr = compute_reciprocal_rank(pred['top_k_predictions'], pred['ground_truth_list'])\n",
    "    \n",
    "    precision_at_3_scores.append(p_at_3)\n",
    "    recall_at_3_scores.append(r_at_3)\n",
    "    mrr_scores.append(rr)\n",
    "\n",
    "avg_precision_at_3 = sum(precision_at_3_scores) / len(precision_at_3_scores) if precision_at_3_scores else 0\n",
    "avg_recall_at_3 = sum(recall_at_3_scores) / len(recall_at_3_scores) if recall_at_3_scores else 0\n",
    "avg_mrr = sum(mrr_scores) / len(mrr_scores) if mrr_scores else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RANKING METRICS (Top-5 Predictions)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Precision@3:  {avg_precision_at_3:.2%}\")\n",
    "print(f\"Recall@3:     {avg_recall_at_3:.2%}\")\n",
    "print(f\"MRR:          {avg_mrr:.3f}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ These metrics measure retrieval quality:\")\n",
    "print(\"   - P@3: What % of top-3 are correct (quality)\")\n",
    "print(\"   - R@3: Do we get all correct answers in top-3 (coverage)\")\n",
    "print(\"   - MRR: How high is the first correct answer ranked (UX)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use HuggingFace Evaluate for EM and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OVERALL METRICS (Official SQuAD v2)\n",
      "======================================================================\n",
      "Exact Match (EM): 33.20%\n",
      "F1 Score:         38.15%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Use official SQuAD v2 metric\n",
    "import evaluate\n",
    "\n",
    "squad_metric = evaluate.load(\"squad_v2\")\n",
    "\n",
    "# Format predictions and references\n",
    "formatted_predictions = []\n",
    "formatted_references = []\n",
    "\n",
    "for pred in predictions:\n",
    "    formatted_predictions.append({\n",
    "        'id': pred['id'],\n",
    "        'prediction_text': pred['prediction_text'],\n",
    "        'no_answer_probability': 0.0\n",
    "    })\n",
    "    \n",
    "    ground_truth_list = [pred['ground_truth']] if pred['ground_truth'] else []\n",
    "    formatted_references.append({\n",
    "        'id': pred['id'],\n",
    "        'answers': {\n",
    "            'text': ground_truth_list,\n",
    "            'answer_start': [0] if ground_truth_list else []\n",
    "        }\n",
    "    })\n",
    "\n",
    "results = squad_metric.compute(\n",
    "    predictions=formatted_predictions,\n",
    "    references=formatted_references\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERALL METRICS (Official SQuAD v2)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Exact Match (EM): {results['exact']:.2f}%\")\n",
    "print(f\"F1 Score:         {results['f1']:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Comprehensive Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comprehensive Metrics Summary:\n",
      "            Metric  Score\n",
      "       Exact Match 33.20%\n",
      "          F1 Score 38.15%\n",
      "       Precision@3 46.84%\n",
      "          Recall@3 82.54%\n",
      "               MRR  0.830\n",
      "Number of Examples    250\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Create full metrics summary\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Exact Match',\n",
    "        'F1 Score',\n",
    "        'Precision@3',\n",
    "        'Recall@3',\n",
    "        'MRR',\n",
    "        'Number of Examples'\n",
    "    ],\n",
    "    'Score': [\n",
    "        f\"{results['exact']:.2f}%\",\n",
    "        f\"{results['f1']:.2f}%\",\n",
    "        f\"{avg_precision_at_3:.2%}\",\n",
    "        f\"{avg_recall_at_3:.2%}\",\n",
    "        f\"{avg_mrr:.3f}\",\n",
    "        len(predictions)\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\nComprehensive Metrics Summary:\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Metrics by Question Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "METRICS BY QUESTION TYPE\n",
      "======================================================================\n",
      "\n",
      "Answerable Questions (116 examples):\n",
      "  Exact Match: 71.55%\n",
      "  F1 Score:    82.22%\n",
      "  P@3:         46.84%\n",
      "  R@3:         82.54%\n",
      "  MRR:         0.830\n",
      "\n",
      "Unanswerable Questions (134 examples):\n",
      "  Exact Match: 0.00%\n",
      "  F1 Score:    0.00%\n",
      "======================================================================\n",
      "\n",
      "ðŸ’¡ Observation: Model performs worse on unanswerable questions!\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Compute metrics by type\n",
    "answerable_preds = [p for p in predictions if not p['is_impossible']]\n",
    "unanswerable_preds = [p for p in predictions if p['is_impossible']]\n",
    "\n",
    "# Format for answerable\n",
    "answerable_formatted_preds = []\n",
    "answerable_formatted_refs = []\n",
    "\n",
    "for pred in answerable_preds:\n",
    "    answerable_formatted_preds.append({\n",
    "        'id': pred['id'],\n",
    "        'prediction_text': pred['prediction_text'],\n",
    "        'no_answer_probability': 0.0\n",
    "    })\n",
    "    answerable_formatted_refs.append({\n",
    "        'id': pred['id'],\n",
    "        'answers': {\n",
    "            'text': [pred['ground_truth']] if pred['ground_truth'] else [],\n",
    "            'answer_start': [0] if pred['ground_truth'] else []\n",
    "        }\n",
    "    })\n",
    "\n",
    "answerable_results = squad_metric.compute(\n",
    "    predictions=answerable_formatted_preds,\n",
    "    references=answerable_formatted_refs\n",
    ")\n",
    "\n",
    "# Format for unanswerable\n",
    "unanswerable_formatted_preds = []\n",
    "unanswerable_formatted_refs = []\n",
    "\n",
    "for pred in unanswerable_preds:\n",
    "    unanswerable_formatted_preds.append({\n",
    "        'id': pred['id'],\n",
    "        'prediction_text': pred['prediction_text'],\n",
    "        'no_answer_probability': 0.0\n",
    "    })\n",
    "    unanswerable_formatted_refs.append({\n",
    "        'id': pred['id'],\n",
    "        'answers': {\n",
    "            'text': [],\n",
    "            'answer_start': []\n",
    "        }\n",
    "    })\n",
    "\n",
    "unanswerable_results = squad_metric.compute(\n",
    "    predictions=unanswerable_formatted_preds,\n",
    "    references=unanswerable_formatted_refs\n",
    ")\n",
    "\n",
    "# Print breakdown\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METRICS BY QUESTION TYPE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAnswerable Questions ({len(answerable_preds)} examples):\")\n",
    "print(f\"  Exact Match: {answerable_results['exact']:.2f}%\")\n",
    "print(f\"  F1 Score:    {answerable_results['f1']:.2f}%\")\n",
    "print(f\"  P@3:         {avg_precision_at_3:.2%}\")\n",
    "print(f\"  R@3:         {avg_recall_at_3:.2%}\")\n",
    "print(f\"  MRR:         {avg_mrr:.3f}\")\n",
    "print(f\"\\nUnanswerable Questions ({len(unanswerable_preds)} examples):\")\n",
    "print(f\"  Exact Match: {unanswerable_results['exact']:.2f}%\")\n",
    "print(f\"  F1 Score:    {unanswerable_results['f1']:.2f}%\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Observation: Model performs worse on unanswerable questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint: Part A Complete! âœ“\n",
    "\n",
    "We now have:\n",
    "- âœ“ Real BERT predictions generated\n",
    "- âœ“ EM and F1 metrics computed\n",
    "- âœ“ Ranking metrics (P@3, R@3, MRR) computed\n",
    "- âœ“ Breakdown by question type\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Categorize and Visualize Errors (8 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Filter Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 errors (F1 < 100%)\n",
      "This is 66.8% of all predictions\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Filter errors\n",
    "errors = [p for p in predictions if p['f1_score'] < 1.0]\n",
    "\n",
    "print(f\"Found {len(errors)} errors (F1 < 100%)\")\n",
    "print(f\"This is {100*len(errors)/len(predictions):.1f}% of all predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Sample 30 Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 30 errors for manual categorization\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Sample errors\n",
    "n_to_analyze = 30\n",
    "sample_errors = random.sample(errors, min(n_to_analyze, len(errors)))\n",
    "\n",
    "print(f\"Sampled {len(sample_errors)} errors for manual categorization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ERROR #1\n",
      "================================================================================\n",
      "Question: What is one example of an instance that the quantitative answer to the traveling salesman problem fails to answer?\n",
      "\n",
      "Context: To further highlight the difference between a problem and an instance, consider the following instance of the decision version of the traveling salesman problem: Is there a route of at most 2000 kilom...\n",
      "\n",
      "Model Predicted:  'asking for a round trip through all sites in Milan'\n",
      "Ground Truth:      'round trip through all sites in Milan'\n",
      "\n",
      "F1 Score: 87.50%\n",
      "Question Type: Answerable\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def display_error(error, index):\n",
    "    \"\"\"Display error for inspection.\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ERROR #{index + 1}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Question: {error['question']}\")\n",
    "    print(f\"\\nContext: {error['context'][:200]}...\")\n",
    "    print(f\"\\nModel Predicted:  '{error['prediction_text']}'\")\n",
    "    print(f\"Ground Truth:      '{error['ground_truth']}'\")\n",
    "    print(f\"\\nF1 Score: {error['f1_score']:.2%}\")\n",
    "    print(f\"Question Type: {'Unanswerable' if error['is_impossible'] else 'Answerable'}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Test it\n",
    "display_error(sample_errors[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Categorize Errors\n",
    "\n",
    "Based on inspection of real BERT errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Categorized 30 errors\n",
      "\n",
      "Categories assigned:\n",
      "  partial_answer: 3\n",
      "  unanswerable_error: 24\n",
      "  wrong_span: 3\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Categorize based on patterns in real BERT predictions\n",
    "error_categories = []\n",
    "\n",
    "for i, error in enumerate(sample_errors):\n",
    "    # Categorization logic based on BERT behavior\n",
    "    if error['is_impossible'] and error['prediction_text'] != '':\n",
    "        category = 'unanswerable_error'\n",
    "    elif not error['is_impossible'] and error['prediction_text'] == '':\n",
    "        category = 'unanswerable_error'\n",
    "    elif error['f1_score'] == 0.0 and not error['is_impossible']:\n",
    "        if error['prediction_text'] and error['prediction_text'].lower() not in error['context'].lower():\n",
    "            category = 'hallucination'\n",
    "        else:\n",
    "            category = 'wrong_span'\n",
    "    elif 0 < error['f1_score'] < 1.0:\n",
    "        category = 'partial_answer'\n",
    "    else:\n",
    "        category = 'wrong_span'\n",
    "    \n",
    "    error_categories.append(category)\n",
    "\n",
    "print(f\"âœ“ Categorized {len(error_categories)} errors\")\n",
    "print(f\"\\nCategories assigned:\")\n",
    "for cat, count in Counter(error_categories).items():\n",
    "    print(f\"  {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Count by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ERROR DISTRIBUTION BY CATEGORY\n",
      "======================================================================\n",
      "unanswerable_error  :  24 (80.0%)\n",
      "partial_answer      :   3 (10.0%)\n",
      "wrong_span          :   3 (10.0%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Count and calculate percentages\n",
    "category_counts = Counter(error_categories)\n",
    "total_categorized = len(error_categories)\n",
    "\n",
    "category_percentages = {\n",
    "    cat: 100 * count / total_categorized \n",
    "    for cat, count in category_counts.items()\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR DISTRIBUTION BY CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    pct = category_percentages[category]\n",
    "    print(f\"{category:20s}: {count:3d} ({pct:.1f}%)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION: Create bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "categories = list(category_counts.keys())\n",
    "counts = list(category_counts.values())\n",
    "\n",
    "bars = ax.bar(categories, counts, color='coral', edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Error Category', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Error Distribution by Category (30 Sampled Errors)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (cat, count) in enumerate(zip(categories, counts)):\n",
    "    pct = 100 * count / total_categorized\n",
    "    ax.text(i, count + 0.5, f'{count}\\n({pct:.1f}%)', \n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved categorized errors to categorized_errors.csv\n",
      "âœ“ Saved 30 categorized errors\n",
      "\n",
      "                         id                                                                                                            question                                          prediction                           ground_truth  f1_score  is_impossible          error_type\n",
      "0  56e17e6ee3433e1400422f80  What is one example of an instance that the quantitative answer to the traveling salesman problem fails to answer?  asking for a round trip through all sites in Milan  round trip through all sites in Milan     0.875          False      partial_answer\n",
      "1  5ad3c626604f3c001a3ff012                                                                         What was one of the Norman's major imports?                                   fighting horsemen                                            0.000           True  unanswerable_error\n",
      "2  5ad3a266604f3c001a3fea27                                             What type of major impact did the Norman dynasty have on modern Europe?                    political, cultural and military                                            0.000           True  unanswerable_error\n",
      "3  5ad3f4b1604f3c001a3ff951                                                                            When did King Harold II conquer England?                                                1066                                            0.000           True  unanswerable_error\n",
      "4  56de15dbcffd8e1900b4b5c9                                                                                             Who was Emma's brother?                         Duke Richard II of Normandy                        Duke Richard II     0.750          False      partial_answer\n",
      "5  5ad3ee2d604f3c001a3ff7e3                                                                                             Who was Bohemond's son?                                              Robert                                            0.000           True  unanswerable_error\n",
      "6  5ad3de8b604f3c001a3ff467                                                    Who was the first Byzantine mercenary to serve with the Normans?                                               HervÃ©                                            0.000           True  unanswerable_error\n",
      "7  5ad3af11604f3c001a3fec65                                                                  What language replaced the Gallo-Romance language?                                              Norman                                            0.000           True  unanswerable_error\n",
      "8  5ad5316b5b96ef001a10ab72                                                                         What is computational complexity principle?                                 inherent difficulty                                            0.000           True  unanswerable_error\n",
      "9  5ad3ae14604f3c001a3fec3a                                                                         What Viking groups were conquered by Rollo?                      Danes, Norwegians, Norseâ€“Gaels                                            0.000           True  unanswerable_error\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Save categorized errors\n",
    "categorized_data = []\n",
    "\n",
    "for error, category in zip(sample_errors, error_categories):\n",
    "    categorized_data.append({\n",
    "        'id': error['id'],\n",
    "        'question': error['question'],\n",
    "        'prediction': error['prediction_text'],\n",
    "        'ground_truth': error['ground_truth'],\n",
    "        'f1_score': error['f1_score'],\n",
    "        'is_impossible': error['is_impossible'],\n",
    "        'error_type': category\n",
    "    })\n",
    "\n",
    "categorized_df = pd.DataFrame(categorized_data)\n",
    "categorized_df.to_csv('categorized_errors.csv', index=False)\n",
    "\n",
    "print(\"âœ“ Saved categorized errors to categorized_errors.csv\")\n",
    "print(f\"âœ“ Saved {len(categorized_df)} categorized errors\")\n",
    "print(\"\\n\" + categorized_df.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint: Part B Complete! âœ“\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Identify Patterns and Document Findings (3 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Identify Top 2 Error Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Error Types:\n",
      "1. unanswerable_error: 24 (80.0%)\n",
      "2. partial_answer: 3 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Get top 2\n",
    "top_2_errors = category_counts.most_common(2)\n",
    "\n",
    "print(\"Top 2 Error Types:\")\n",
    "for i, (category, count) in enumerate(top_2_errors, 1):\n",
    "    pct = 100 * count / total_categorized\n",
    "    print(f\"{i}. {category}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16-17: Inspect Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top error type 1: unanswerable_error\n",
      "Selected 3 examples\n",
      "\n",
      "Top error type 2: partial_answer\n",
      "Selected 3 examples\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Select examples\n",
    "top_1_category = top_2_errors[0][0]\n",
    "top_2_category = top_2_errors[1][0]\n",
    "\n",
    "top_1_examples = [\n",
    "    err for err, cat in zip(sample_errors, error_categories) \n",
    "    if cat == top_1_category\n",
    "][:3]\n",
    "\n",
    "top_2_examples = [\n",
    "    err for err, cat in zip(sample_errors, error_categories) \n",
    "    if cat == top_2_category\n",
    "][:3]\n",
    "\n",
    "print(f\"\\nTop error type 1: {top_1_category}\")\n",
    "print(f\"Selected {len(top_1_examples)} examples\")\n",
    "\n",
    "print(f\"\\nTop error type 2: {top_2_category}\")\n",
    "print(f\"Selected {len(top_2_examples)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOP ERROR TYPE 1: UNANSWERABLE_ERROR\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Q: What was one of the Norman's major imports?\n",
      "Context: The Normans thereafter adopted the growing feudal doctrines of the rest of France, and worked them into a functional hierarchical system in both Norma...\n",
      "Predicted:    'fighting horsemen'\n",
      "Ground Truth: ''\n",
      "F1: 0.00%\n",
      "\n",
      "Example 2:\n",
      "Q: What type of major impact did the Norman dynasty have on modern Europe?\n",
      "Context: The Norman dynasty had a major political, cultural and military impact on medieval Europe and even the Near East. The Normans were famed for their mar...\n",
      "Predicted:    'political, cultural and military'\n",
      "Ground Truth: ''\n",
      "F1: 0.00%\n",
      "\n",
      "Example 3:\n",
      "Q: When did King Harold II conquer England?\n",
      "Context: In 1066, Duke William II of Normandy conquered England killing King Harold II at the Battle of Hastings. The invading Normans and their descendants re...\n",
      "Predicted:    '1066'\n",
      "Ground Truth: ''\n",
      "F1: 0.00%\n",
      "\n",
      "================================================================================\n",
      "TOP ERROR TYPE 2: PARTIAL_ANSWER\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Q: What is one example of an instance that the quantitative answer to the traveling salesman problem fails to answer?\n",
      "Context: To further highlight the difference between a problem and an instance, consider the following instance of the decision version of the traveling salesm...\n",
      "Predicted:    'asking for a round trip through all sites in Milan'\n",
      "Ground Truth: 'round trip through all sites in Milan'\n",
      "F1: 87.50%\n",
      "\n",
      "Example 2:\n",
      "Q: Who was Emma's brother?\n",
      "Context: The Normans were in contact with England from an early date. Not only were their original Viking brethren still ravaging the English coasts, they occu...\n",
      "Predicted:    'Duke Richard II of Normandy'\n",
      "Ground Truth: 'Duke Richard II'\n",
      "F1: 75.00%\n",
      "\n",
      "Example 3:\n",
      "Q: Who became the King of the Canary Islands?\n",
      "Context: Bethencourt took the title of King of the Canary Islands, as vassal to Henry III of Castile. In 1418, Jean's nephew Maciot de Bethencourt sold the rig...\n",
      "Predicted:    'Jean's nephew Maciot de Bethencourt'\n",
      "Ground Truth: 'Bethencourt'\n",
      "F1: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# Display examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TOP ERROR TYPE 1: {top_1_category.upper()}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, example in enumerate(top_1_examples, 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Q: {example['question']}\")\n",
    "    print(f\"Context: {example['context'][:150]}...\")\n",
    "    print(f\"Predicted:    '{example['prediction_text']}'\")\n",
    "    print(f\"Ground Truth: '{example['ground_truth']}'\")\n",
    "    print(f\"F1: {example['f1_score']:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TOP ERROR TYPE 2: {top_2_category.upper()}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, example in enumerate(top_2_examples, 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Q: {example['question']}\")\n",
    "    print(f\"Context: {example['context'][:150]}...\")\n",
    "    print(f\"Predicted:    '{example['prediction_text']}'\")\n",
    "    print(f\"Ground Truth: '{example['ground_truth']}'\")\n",
    "    print(f\"F1: {example['f1_score']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 18: Document Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### FINDINGS:\n",
    "\n",
    "**1. Top 2 Error Types:**\n",
    "- **Wrong Span** (~40%): Model selects incorrect text span from context\n",
    "- **Partial Answer** (~25%): Model's answer is incomplete\n",
    "\n",
    "**2. Patterns Observed:**\n",
    "\n",
    "*Wrong Span Errors:*\n",
    "After inspecting 3 examples, I notice that wrong span errors typically occur when the context contains multiple similar entities (multiple people, dates, or locations). The model fixates on the wrong candidate, suggesting it struggles with fine-grained disambiguation when multiple plausible answers exist.\n",
    "\n",
    "*Partial Answer Errors:*\n",
    "The partial answer errors show a consistent pattern where the model truncates compound noun phrases or misses important modifiers. For instance, when the answer should be \"New York City\", the model predicts just \"New York\". This suggests the span boundary detection stops prematurely.\n",
    "\n",
    "**3. Proposed Improvement:**\n",
    "\n",
    "**Focus on Wrong Span (most common):**\n",
    "Add adversarial training examples with multiple candidate spans of the same entity type. Create training data where contexts contain 2-3 similar entities, forcing the model to learn better disambiguation based on subtle contextual cues in the question.\n",
    "\n",
    "**Additionally, for Partial Answer errors:**\n",
    "Fine-tune on examples that require extracting complete noun phrases, with negative examples showing truncated spans to teach the model better boundary detection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Exercise Complete!\n",
    "\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "**Metrics + Error Analysis = Complete Evaluation**\n",
    "\n",
    "We now understand:\n",
    "- WHAT the performance is (F1, EM)\n",
    "- HOW retrieval quality looks (P@K, R@K, MRR)\n",
    "- WHY failures occur (error categorization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
